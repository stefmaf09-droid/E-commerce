name: Recours E-commerce CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        # Ensure PyPDF2 is available for PDF text extraction in tests
        pip install PyPDF2>=3.0.0
        pip install pytest pytest-asyncio pytest-cov black flake8

- name: Security: pip-audit (generate JSON)
      run: |
        # Install pip-audit and produce a JSON report for artifact upload.
        python -m pip install --upgrade pip
        pip install pip-audit
        pip-audit --format json --output pip-audit.json

    - name: Upload pip-audit report
      uses: actions/upload-artifact@v4
      with:
        name: pip-audit-report-${{ github.run_id }}
        path: pip-audit.json

    - name: Comment on PR with pip-audit summary (if PR)
      if: ${{ github.event_name == 'pull_request' }}
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        REPO: ${{ github.repository }}
        EVENT_PATH: ${{ github.event_path }}
      run: |
        python - <<'PY'
        import os, json, sys, requests
        repo = os.environ['REPO']
        token = os.environ['GITHUB_TOKEN']
        try:
            with open('pip-audit.json') as f:
                data = json.load(f)
        except Exception as e:
            print('Could not read pip-audit.json:', e)
            sys.exit(0)
        levels = {'low':0,'medium':1,'high':2,'critical':3}
        entries = []
        for item in data:
            for v in item.get('vulns', []):
                sev = v.get('severity','').lower()
                if levels.get(sev, -1) >= 1:
                    entries.append((sev, item.get('name'), v.get('id')))
        if not entries:
            print('No vulns >= medium to report.')
            sys.exit(0)
        # load event to get PR number
        event_path = os.environ.get('GITHUB_EVENT_PATH')
        try:
            with open(event_path) as ef:
                ev = json.load(ef)
        except Exception:
            ev = {}
        pr = ev.get('pull_request', {}).get('number') or ev.get('number')
        if not pr:
            print('No PR number in event payload; skipping comment.')
            sys.exit(0)
        body = '### ⚠️ pip-audit report (vulnerabilities >= medium)\n\n'
        for sev,name,vid in entries:
            body += f'- **{name}** — severity **{sev}** — {vid}\n'
        body += '\n_This comment was posted automatically by the `pip-audit` workflow._'
        url = f'https://api.github.com/repos/{repo}/issues/{pr}/comments'
        r = requests.post(url, headers={'Authorization':f'token {token}','Accept':'application/vnd.github+json'}, json={'body': body}, timeout=15)
        if r.status_code not in (200,201):
            print('Failed to post comment', r.status_code, r.text)
            sys.exit(1)
        print('Comment posted to PR', pr)
        PY
            sys.exit(1)
        max_sev = {'low':0,'medium':1,'high':2,'critical':3}
        found = False
        for item in r:
            for vuln in item.get('vulns', []):
                sev = vuln.get('severity','').lower()
                if max_sev.get(sev, -1) >= 2:
                    print('VULN:', item.get('name'), 'severity=', sev, 'id=', vuln.get('id'))
                    found = True
        if found:
            print('One or more vulnerabilities with severity >= high were found. Failing the job.')
            sys.exit(1)
        print('No vulnerabilities >= high found.')
        PY
        
    - name: Lint with flake8
      run: |
        flake8 src --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 src --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: Run tests with coverage
      run: |
        pytest --cov=src --cov-report=xml
        
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        fail_ci_if_error: false
      env:
        CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  # CodeQL static analysis job (runs in parallel with tests)
  codeql:
    name: CodeQL Analysis
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Initialize CodeQL
        uses: github/codeql-action/init@v2
        with:
          languages: python

      - name: Autobuild (best-effort)
        uses: github/codeql-action/autobuild@v2
        # For Python projects autobuild is usually a no-op but safe to include

      - name: Run CodeQL Analysis
        uses: github/codeql-action/analyze@v2

  e2e:
    name: E2E Playwright (Onboarding smoke)
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies & Playwright browsers
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest
          python -m playwright install --with-deps

      - name: Start Streamlit (background)
        run: |
          nohup streamlit run dashboard.py --server.port 8510 > streamlit_e2e.log 2>&1 &
          # wait for streamlit to respond
          for i in {1..60}; do
            curl -sSf http://localhost:8510/ && break || sleep 1
          done

      - name: Run onboarding e2e tests
        run: |
          pytest tests/e2e/test_onboarding_playwright.py -q

      - name: Upload streamlit log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: streamlit-e2e-log-${{ github.run_id }}
          path: streamlit_e2e.log

  deploy_staging:
    needs: test
    if: github.ref == 'refs/heads/develop'
    runs-on: ubuntu-latest
    steps:
    - name: Deploy to Staging
      run: echo "Deploying to staging environment..."
      
  deploy_production:
    needs: test
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
    - name: Deploy to Production
      run: echo "Deploying to production environment..."
